<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Static EQ Curve Comparator</title>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-zoom"></script>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      line-height: 1.6;
      color: #333;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f8f9fa;
    }

    h2 {
      color: #2c3e50;
      margin-bottom: 1.5rem;
      font-size: 2rem;
      border-bottom: 2px solid #e9ecef;
      padding-bottom: 0.5rem;
    }

    h3 {
      color: #2c3e50;
      margin: 1.5rem 0 1rem;
      font-size: 1.5rem;
    }

    .section {
      background: white;
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    .file-input-container {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-bottom: 10px;
    }

    .file-input-container input[type="file"] {
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background: white;
    }

    .file-input-container span {
      color: #666;
      font-size: 0.9rem;
    }

    .waveform-container {
      margin: 20px 0;
      position: relative;
      display: flex;
      align-items: center;
      gap: 10px;
      background: white;
      padding: 15px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    .waveform-wrapper {
      position: relative;
      flex-grow: 1;
    }

    .waveform {
      border: 1px solid #e9ecef;
      border-radius: 4px;
      cursor: pointer;
      width: 100%;
      height: 100px;
      background: #f8f9fa;
    }

    .selection {
      position: absolute;
      top: 0;
      height: 100%;
      background: rgba(0, 123, 255, 0.1);
      border: 1px solid #007bff;
      pointer-events: none;
      border-radius: 4px;
    }

    .chart-controls {
      margin: 15px 0;
      display: flex;
      gap: 10px;
    }

    .chart-controls button {
      padding: 8px 16px;
      border: none;
      border-radius: 4px;
      background: #007bff;
      color: white;
      cursor: pointer;
      transition: background-color 0.2s;
    }

    .chart-controls button:hover {
      background: #0056b3;
    }

    .analysis-controls {
      margin: 15px 0;
      display: flex;
      align-items: center;
      gap: 15px;
      background: white;
      padding: 15px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    .analysis-controls label {
      min-width: 150px;
      color: #495057;
      font-weight: 500;
    }

    .analysis-controls input[type="range"] {
      flex: 1;
    }

    .play-button {
      width: 40px;
      height: 40px;
      border-radius: 50%;
      border: 2px solid #007bff;
      background: white;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 20px;
      user-select: none;
      flex-shrink: 0;
      color: #007bff;
      transition: all 0.2s;
    }

    .play-button:hover {
      background: #007bff;
      color: white;
    }

    .play-button:active {
      transform: scale(0.95);
    }

    #eqChart {
      background: white;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
      margin: 20px 0;
    }

    .mixing-advice-section {
      background: white;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }

    .mixing-advice-section input[type="password"],
    .mixing-advice-section input[type="text"] {
      width: 100%;
      padding: 8px;
      margin: 5px 0;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-size: 14px;
    }

    .mixing-advice-section button {
      padding: 8px 16px;
      background: #28a745;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      transition: background-color 0.2s;
    }

    .mixing-advice-section button:hover {
      background: #218838;
    }

    .mixing-advice-section button:disabled {
      background: #6c757d;
      cursor: not-allowed;
    }

    #mixingAdvice {
      width: 100%;
      height: 400px;
      padding: 15px;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      font-size: 14px;
      line-height: 1.6;
      border: 1px solid #ddd;
      border-radius: 4px;
      resize: vertical;
      background: #f8f9fa;
    }

    .github-link {
      display: inline-flex;
      align-items: center;
      gap: 5px;
      color: #0366d6;
      text-decoration: none;
      font-weight: 500;
      margin-bottom: 20px;
    }

    .github-link:hover {
      text-decoration: underline;
    }

    .github-link img {
      width: 16px;
      height: 16px;
    }
  </style>
</head>
<body>
  <h2>Static EQ Curve Comparator</h2>
  <a href="https://github.com/royk/compareeq" target="_blank" class="github-link">
    <img src="https://github.com/favicon.ico" alt="GitHub">
    View on GitHub
  </a>

  <div class="section">
    <div class="file-input-container">
      <input type="file" id="yourTrack" accept="audio/*">
      <span id="yourTrackName"></span>
    </div>
    <div class="waveform-container">
      <button class="play-button" id="yourPlayButton">▶</button>
      <div class="waveform-wrapper">
        <canvas id="yourWaveform" class="waveform"></canvas>
        <div id="yourSelection" class="selection"></div>
      </div>
    </div>
  </div>

  <div class="section">
    <div class="file-input-container">
      <input type="file" id="refTrack" accept="audio/*">
      <span id="refTrackName"></span>
    </div>
    <div class="waveform-container">
      <button class="play-button" id="refPlayButton">▶</button>
      <div class="waveform-wrapper">
        <canvas id="refWaveform" class="waveform"></canvas>
        <div id="refSelection" class="selection"></div>
      </div>
    </div>
  </div>

  <div class="section">
    <div class="analysis-controls">
      <label for="analysisLength">Analysis Length (seconds):</label>
      <input type="range" id="analysisLength" min="0.1" max="5" step="0.1" value="5">
      <span id="analysisLengthValue">5.0</span>
    </div>
    <div class="chart-controls">
      <button onclick="resetZoom()">Reset Zoom</button>
      <button onclick="zoomIn()">Zoom In</button>
      <button onclick="zoomOut()">Zoom Out</button>
    </div>
    <canvas id="eqChart" width="1000" height="400"></canvas>
  </div>

  <div class="mixing-advice-section">
    <div class="analysis-controls">
      <label for="openaiKey">OpenAI API Key:</label>
      <input type="password" id="openaiKey">
      <button id="getAdviceButton" disabled>Get Mixing Advice</button>
    </div>
    <div style="margin: 15px 0;">
      <label for="customPrompt">Additional Context (optional):</label>
      <input type="text" id="customPrompt" placeholder="Add genre, key, or any other relevant information to help with the mixing advice (e.g., 'This is a rock track in E minor, aiming for a warm vintage sound')">
    </div>
    <h3>Mixing Advice</h3>
    <textarea id="mixingAdvice" readonly></textarea>
  </div>

  <script>
    // Global function for getting mixing advice
    async function getMixingAdvice() {
      const apiKey = document.getElementById('openaiKey').value;
      if (!apiKey) {
        document.getElementById('mixingAdvice').value = 'Please enter your OpenAI API key';
        return;
      }

      if (!window.currentChart) {
        document.getElementById('mixingAdvice').value = 'Please analyze audio files first';
        return;
      }

      const button = document.getElementById('getAdviceButton');
      button.disabled = true;
      button.textContent = 'Getting Advice...';
      document.getElementById('mixingAdvice').value = 'Getting mixing advice...';

      try {
        // Get the chart canvas
        const canvas = document.getElementById('eqChart');
        
        // Convert canvas to base64 image
        const imageData = canvas.toDataURL('image/png').split(',')[1]; // Get just the base64 data without the prefix
        
        // Create the prompt
        const analysisLength = document.getElementById('analysisLength').value;
        const customPrompt = document.getElementById('customPrompt').value;
        const prompt = `I have analyzed two audio tracks and found the frequency differences shown in this chart. The blue line is the first track, and the green line is the reference track. This analysis is an average over ${analysisLength} seconds of audio, with LUFs matched.${customPrompt ? ` Additional context: ${customPrompt}` : ''} Please provide specific mixing advice on what changes, if any, you would make to the first track based on the reference track. Please provide specific EQ recommendations and mixing tips to help get the first track to sound professional, based on that the reference track is a professional mix.`;

        // Send to OpenAI
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: 'gpt-4.1-mini',
            messages: [
              {
                role: 'system',
                content: 'You are an expert audio engineer with deep knowledge of mixing and EQ. Provide specific, actionable advice for mixing the first track to sound professional, based on that the reference track is a professional mix.'
              },
              {
                role: 'user',
                content: [
                  { type: "text", text: prompt },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:image/png;base64,${imageData}`
                    }
                  }
                ]
              }
            ],
            max_tokens: 5000
          })
        });

        const data = await response.json();
        if (data.choices && data.choices[0]) {
          document.getElementById('mixingAdvice').value = data.choices[0].message.content;
        } else {
          throw new Error('No response from OpenAI');
        }
      } catch (error) {
        console.error('Error getting mixing advice:', error);
        document.getElementById('mixingAdvice').value = 'Error getting mixing advice. Please check your API key and try again.';
      } finally {
        button.disabled = false;
        button.textContent = 'Get Mixing Advice';
      }
    }

    // Add event listener for the advice button
    document.getElementById('getAdviceButton').addEventListener('click', getMixingAdvice);

    // Add event listener for API key input
    document.getElementById('openaiKey').addEventListener('input', (e) => {
      document.getElementById('getAdviceButton').disabled = !e.target.value;
    });

    // Read API key from URL parameters
    const urlParams = new URLSearchParams(window.location.search);
    const apiKey = urlParams.get('key');
    if (apiKey) {
      document.getElementById('openaiKey').value = apiKey;
      document.getElementById('getAdviceButton').disabled = false;
    }
  </script>

  <script type="module">
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const windowSize = 2048;
    let yourBuffer = null;
    let refBuffer = null;
    let yourStartSample = 0;
    let refStartSample = 0;
    window.currentChart = null;  // Make currentChart globally accessible
    let analysisLength = 5.0; // Default analysis length in seconds
    let yourSource = null;
    let refSource = null;
    let yourPlayButton = null;
    let refPlayButton = null;

    // Setup play buttons
    function setupPlayButton(button, buffer, startSample) {
      if (button.id === 'yourPlayButton') {
        yourPlayButton = { button, buffer, startSample };
      } else {
        refPlayButton = { button, buffer, startSample };
      }

      button.addEventListener('mousedown', () => {
        if (!buffer) return;
        
        // Create new source
        const source = audioCtx.createBufferSource();
        source.buffer = buffer;
        source.connect(audioCtx.destination);
        
        // Get current start sample
        const currentStart = button.id === 'yourPlayButton' ? yourStartSample : refStartSample;
        
        // Start from the current playhead position
        source.start(0, currentStart / buffer.sampleRate);
        
        // Store source for stopping
        if (button.id === 'yourPlayButton') {
          yourSource = source;
        } else {
          refSource = source;
        }
      });

      button.addEventListener('mouseup', () => {
        const source = button.id === 'yourPlayButton' ? yourSource : refSource;
        if (source) {
          source.stop();
          if (button.id === 'yourPlayButton') {
            yourSource = null;
          } else {
            refSource = null;
          }
        }
      });

      // Also stop on mouseleave in case user moves mouse away while holding
      button.addEventListener('mouseleave', () => {
        const source = button.id === 'yourPlayButton' ? yourSource : refSource;
        if (source) {
          source.stop();
          if (button.id === 'yourPlayButton') {
            yourSource = null;
          } else {
            refSource = null;
          }
        }
      });
    }

    // Update play button start position
    function updatePlayButtonStart(button, startSample) {
      if (button.id === 'yourPlayButton') {
        yourStartSample = startSample;
      } else {
        refStartSample = startSample;
      }
    }

    // Convert frequency to note name
    function freqToNote(freq) {
      const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
      const a4 = 440; // A4 = 440Hz
      const a4Index = 69; // MIDI note number for A4
      
      if (freq < 20) return ''; // Too low to be a note
      
      // Calculate MIDI note number
      const midiNote = Math.round(12 * Math.log2(freq / a4) + a4Index);
      
      // Get note name and octave
      const noteName = noteNames[midiNote % 12];
      const octave = Math.floor(midiNote / 12) - 1;
      
      return `${noteName}${octave}`;
    }

    // Update analysis length display
    document.getElementById('analysisLength').addEventListener('input', (e) => {
      analysisLength = parseFloat(e.target.value);
      document.getElementById('analysisLengthValue').textContent = analysisLength.toFixed(1);
      if (yourBuffer && refBuffer) analyze();
    });

    // Make zoom functions available globally
    window.resetZoom = function() {
      if (window.currentChart) {
        window.currentChart.resetZoom();
      }
    };

    window.zoomIn = function() {
      if (window.currentChart) {
        window.currentChart.zoom(1.5);
      }
    };

    window.zoomOut = function() {
      if (window.currentChart) {
        window.currentChart.zoom(0.75);
      }
    };

    async function decodeFile(file) {
      const arrayBuffer = await file.arrayBuffer();
      return await audioCtx.decodeAudioData(arrayBuffer);
    }

    function drawWaveform(canvas, buffer, startSample = 0) {
      const ctx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      const data = buffer.getChannelData(0);
      
      // Clear canvas
      ctx.fillStyle = 'white';
      ctx.fillRect(0, 0, width, height);
      
      // Draw waveform
      ctx.strokeStyle = 'black';
      ctx.lineWidth = 1;
      ctx.beginPath();
      
      const step = Math.ceil(data.length / width);
      const amp = height / 2;
      
      for (let i = 0; i < width; i++) {
        let min = 1.0;
        let max = -1.0;
        for (let j = 0; j < step; j++) {
          const datum = data[i * step + j];
          if (datum < min) min = datum;
          if (datum > max) max = datum;
        }
        ctx.moveTo(i, (1 + min) * amp);
        ctx.lineTo(i, (1 + max) * amp);
      }
      
      ctx.stroke();
      
      // Draw selection
      const selection = canvas.parentElement.querySelector('.selection');
      selection.style.left = (startSample / data.length * width) + 'px';
      selection.style.width = (windowSize / data.length * width) + 'px';
    }

    function getRMS(data, start, size) {
      let sum = 0;
      for (let i = start; i < start + size; i++) {
        const sample = data[i] || 0;
        sum += sample * sample;
      }
      return Math.sqrt(sum / size);
    }

    // Calculate LUFS for a given audio segment
    function calculateLUFS(data, start, size, sampleRate) {
      // K-weighting filter coefficients (simplified)
      const k1 = 1.0;
      const k2 = 1.4;
      const k3 = 1.0;
      
      // Pre-filtering stage
      const filtered = new Float32Array(size);
      for (let i = 0; i < size; i++) {
        const sample = data[start + i] || 0;
        // Simplified K-weighting filter
        filtered[i] = sample * k1 * k2 * k3;
      }
      
      // Calculate RMS with 400ms integration time
      const integrationTime = 0.4; // seconds
      const samplesPerBlock = Math.floor(sampleRate * integrationTime);
      let sum = 0;
      let count = 0;
      
      for (let i = 0; i < size; i += samplesPerBlock) {
        const blockSize = Math.min(samplesPerBlock, size - i);
        let blockSum = 0;
        
        for (let j = 0; j < blockSize; j++) {
          const sample = filtered[i + j];
          blockSum += sample * sample;
        }
        
        sum += Math.sqrt(blockSum / blockSize);
        count++;
      }
      
      // Calculate average and convert to LUFS
      const average = sum / count;
      return -0.691 + 10 * Math.log10(average * average);
    }

    // Match LUFS levels between two segments
    function matchLUFS(data1, start1, size1, data2, start2, size2, sampleRate) {
      const lufs1 = calculateLUFS(data1, start1, size1, sampleRate);
      const lufs2 = calculateLUFS(data2, start2, size2, sampleRate);
      const gainDiff = lufs2 - lufs1;
      return Math.pow(10, gainDiff / 20); // Convert dB to linear gain
    }

    function findLoudestSegment(buffer, windowSize) {
      const data = buffer.getChannelData(0);
      let maxRMS = 0;
      let maxIndex = 0;
      for (let i = 0; i < data.length - windowSize; i += windowSize / 4) {
        const rms = getRMS(data, i, windowSize);
        if (rms > maxRMS) {
          maxRMS = rms;
          maxIndex = i;
        }
      }
      return { startSample: maxIndex, length: windowSize };
    }

    function getFrequencies(sampleRate, fftSize) {
      const freqs = [];
      for (let i = 0; i < fftSize / 2; i++) {
        freqs.push(i * sampleRate / fftSize);
      }
      return freqs;
    }

    function analyzeFFT(buffer, startSample, fftSize) {
      const data = buffer.getChannelData(0);
      const numWindows = Math.floor(fftSize / (windowSize / 2)); // Adjust number of windows based on analysis size
      const windowStep = windowSize / 2; // 50% overlap between windows
      
      // Initialize arrays for averaging
      const realSum = new Float32Array(windowSize);
      const imagSum = new Float32Array(windowSize);
      
      // Process multiple windows across the analysis section
      for (let w = 0; w < numWindows; w++) {
        const windowStart = startSample + (w * windowStep);
        
        // Skip if window would go out of bounds
        if (windowStart < 0 || windowStart + windowSize > data.length) continue;
        
        // Get the audio data for this window
        const windowData = data.slice(windowStart, windowStart + windowSize);
        
        // Apply Hanning window
        const windowedData = new Float32Array(windowSize);
        for (let i = 0; i < windowSize; i++) {
          windowedData[i] = windowData[i] * (0.5 * (1 - Math.cos((2 * Math.PI * i) / (windowSize - 1))));
        }

        // Perform FFT for this window
        const real = new Float32Array(windowSize);
        const imag = new Float32Array(windowSize);
        
        // Copy input data to real array
        for (let i = 0; i < windowSize; i++) {
          real[i] = windowedData[i];
          imag[i] = 0;
        }

        // Cooley-Tukey FFT
        function fft(real, imag) {
          const n = real.length;
          if (n <= 1) return;

          // Divide
          const half = n / 2;
          const realEven = new Float32Array(half);
          const imagEven = new Float32Array(half);
          const realOdd = new Float32Array(half);
          const imagOdd = new Float32Array(half);

          for (let i = 0; i < half; i++) {
            realEven[i] = real[i * 2];
            imagEven[i] = imag[i * 2];
            realOdd[i] = real[i * 2 + 1];
            imagOdd[i] = imag[i * 2 + 1];
          }

          // Conquer
          fft(realEven, imagEven);
          fft(realOdd, imagOdd);

          // Combine
          for (let k = 0; k < half; k++) {
            const angle = -2 * Math.PI * k / n;
            const cos = Math.cos(angle);
            const sin = Math.sin(angle);
            const realTemp = realOdd[k] * cos - imagOdd[k] * sin;
            const imagTemp = realOdd[k] * sin + imagOdd[k] * cos;
            real[k] = realEven[k] + realTemp;
            imag[k] = imagEven[k] + imagTemp;
            real[k + half] = realEven[k] - realTemp;
            imag[k + half] = imagEven[k] - imagTemp;
          }
        }

        fft(real, imag);
        
        // Add to running sum
        for (let i = 0; i < windowSize; i++) {
          realSum[i] += real[i];
          imagSum[i] += imag[i];
        }
      }
      
      // Calculate average magnitude spectrum with frequency-dependent smoothing
      const spectrum = new Float32Array(windowSize / 2);
      const sampleRate = buffer.sampleRate;
      
      for (let i = 0; i < windowSize / 2; i++) {
        const freq = i * sampleRate / windowSize;
        const magnitude = Math.sqrt(realSum[i] * realSum[i] + imagSum[i] * imagSum[i]) / numWindows;
        
        // Calculate smoothing factor based on frequency
        let smoothingFactor = 1;
        if (freq > 1500) {
          // Increase smoothing for frequencies above 1500 Hz
          // Use a logarithmic scale for smooth transition
          const normalizedFreq = (freq - 1500) / (sampleRate/2 - 1500);
          smoothingFactor = 1 + Math.log10(1 + normalizedFreq * 9) * 15; // Smoothing increases with frequency
        }
        
        // Apply smoothing by averaging with neighboring bins
        let smoothedMagnitude = magnitude;
        if (smoothingFactor > 1) {
          const windowSize = Math.floor(smoothingFactor);
          let sum = magnitude;
          let count = 1;
          
          for (let j = 1; j <= windowSize; j++) {
            if (i - j >= 0) {
              const prevMagnitude = Math.sqrt(realSum[i-j] * realSum[i-j] + imagSum[i-j] * imagSum[i-j]) / numWindows;
              sum += prevMagnitude;
              count++;
            }
            if (i + j < windowSize/2) {
              const nextMagnitude = Math.sqrt(realSum[i+j] * realSum[i+j] + imagSum[i+j] * imagSum[i+j]) / numWindows;
              sum += nextMagnitude;
              count++;
            }
          }
          smoothedMagnitude = sum / count;
        }
        
        // Convert to dB, with a small epsilon to avoid log(0)
        spectrum[i] = 20 * Math.log10(smoothedMagnitude + 1e-10);
      }

      return Array.from(spectrum);
    }

    async function process(file, label, color, buffer, startSample, gain = 1.0, analysisSize = windowSize) {
      const spectrum = analyzeFFT(buffer, startSample, analysisSize);
      const freqs = getFrequencies(buffer.sampleRate, windowSize); // Use windowSize for frequency calculation
      // Apply gain to spectrum
      const adjustedSpectrum = spectrum.map(value => value + 20 * Math.log10(gain));
      return { label, freqs, spectrum: adjustedSpectrum, color };
    }

    async function analyze() {
      if (!yourBuffer || !refBuffer) return;

      try {
        // Use the selected analysis length
        const analysisWindowSize = Math.floor(Math.min(yourBuffer.sampleRate, refBuffer.sampleRate) * analysisLength);
        const yourAnalysisStart = Math.max(0, yourStartSample - analysisWindowSize/2);
        const refAnalysisStart = Math.max(0, refStartSample - analysisWindowSize/2);
        
        // Calculate LUFS matching gain using the longer section
        const gain = matchLUFS(
          yourBuffer.getChannelData(0), yourAnalysisStart, analysisWindowSize,
          refBuffer.getChannelData(0), refAnalysisStart, analysisWindowSize,
          yourBuffer.sampleRate
        );

        const [yourData, refData] = await Promise.all([
          process(null, 'Your Track', 'blue', yourBuffer, yourAnalysisStart, gain, analysisWindowSize),
          process(null, 'Reference Track', 'green', refBuffer, refAnalysisStart, 1.0, analysisWindowSize)
        ]);

        const ctx = document.getElementById("eqChart").getContext("2d");
        
        // Destroy previous chart if it exists
        if (window.currentChart) {
          window.currentChart.destroy();
        }

        window.currentChart = new Chart(ctx, {
          type: 'line',
          data: {
            labels: yourData.freqs,
            datasets: [
              {
                label: yourData.label,
                data: yourData.spectrum,
                borderColor: yourData.color,
                borderWidth: 2,
                pointRadius: 0
              },
              {
                label: refData.label,
                data: refData.spectrum,
                borderColor: refData.color,
                borderWidth: 2,
                pointRadius: 0
              }
            ]
          },
          options: {
            scales: {
              x: {
                type: 'logarithmic',
                title: { 
                  display: true, 
                  text: 'Frequency (Hz)',
                  font: {
                    size: 14,
                    weight: 'bold'
                  }
                },
                min: 20,
                max: 20000,
                ticks: {
                  font: {
                    size: 12
                  },
                  callback: function(value) {
                    if (value >= 1000) {
                      return (value/1000) + 'k';
                    }
                    return value;
                  }
                },
                grid: {
                  color: 'rgba(0, 0, 0, 0.1)'
                }
              },
              y: {
                title: { 
                  display: true, 
                  text: 'Magnitude (dB)',
                  font: {
                    size: 14,
                    weight: 'bold'
                  }
                },
                min: function(context) {
                  const chart = context.chart;
                  const {min, max} = chart.scales.y;
                  const range = max - min;
                  return min - range * 0.1;
                },
                max: function(context) {
                  const chart = context.chart;
                  const {min, max} = chart.scales.y;
                  const range = max - min;
                  return max + range * 0.1;
                },
                ticks: {
                  font: {
                    size: 12
                  }
                },
                grid: {
                  color: 'rgba(0, 0, 0, 0.1)'
                }
              }
            },
            responsive: false,
            interaction: {
              mode: 'index',
              intersect: false
            },
            plugins: {
              legend: {
                position: 'top',
                labels: {
                  font: {
                    size: 14,
                    weight: 'bold'
                  },
                  padding: 20
                }
              },
              zoom: {
                pan: {
                  enabled: true,
                  mode: 'xy'
                },
                zoom: {
                  wheel: {
                    enabled: true,
                  },
                  pinch: {
                    enabled: true
                  },
                  mode: 'xy',
                }
              },
              tooltip: {
                enabled: true,
                mode: 'index',
                intersect: false,
                callbacks: {
                  title: function(context) {
                    const freq = parseFloat(context[0].label.replace(/,/g, ''));
                    const note = freqToNote(freq);
                    if (freq >= 1000) {
                      return `Frequency: ${(freq/1000).toFixed(1)} kHz${note ? ` (${note})` : ''}`;
                    }
                    return `Frequency: ${Math.round(freq)} Hz${note ? ` (${note})` : ''}`;
                  },
                  label: function(context) {
                    const dataset = context.dataset;
                    const value = context.raw;
                    return `${dataset.label}: ${value.toFixed(1)} dB`;
                  },
                  afterBody: function(context) {
                    if (context.length > 1) {
                      const diff = context[1].raw - context[0].raw;
                      return [`Difference: ${diff.toFixed(1)} dB`];
                    }
                    return [];
                  }
                }
              }
            }
          }
        });
      } catch (error) {
        console.error('Error analyzing audio:', error);
      }
    }

    document.getElementById("yourTrack").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (file) {
        document.getElementById("yourTrack").style.display = "none";
        document.getElementById("yourTrackName").textContent = file.name;
        
        yourBuffer = await decodeFile(file);
        const { startSample } = findLoudestSegment(yourBuffer, windowSize);
        yourStartSample = startSample;
        const canvas = document.getElementById("yourWaveform");
        canvas.width = canvas.parentElement.clientWidth;
        canvas.height = 100;
        drawWaveform(canvas, yourBuffer, yourStartSample);
        
        // Setup interaction after buffer is loaded
        canvas.onclick = (e) => {
          const rect = canvas.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const newStartSample = Math.floor((x / rect.width) * yourBuffer.length);
          yourStartSample = newStartSample;
          drawWaveform(canvas, yourBuffer, yourStartSample);
          if (refBuffer) analyze(); // Only analyze if both files are loaded
        };

        // Setup play button
        setupPlayButton(document.getElementById("yourPlayButton"), yourBuffer, yourStartSample);

        // Run analysis if reference file is already loaded
        if (refBuffer) analyze();
      }
    });

    document.getElementById("refTrack").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (file) {
        document.getElementById("refTrack").style.display = "none";
        document.getElementById("refTrackName").textContent = file.name;
        
        refBuffer = await decodeFile(file);
        const { startSample } = findLoudestSegment(refBuffer, windowSize);
        refStartSample = startSample;
        const canvas = document.getElementById("refWaveform");
        canvas.width = canvas.parentElement.clientWidth;
        canvas.height = 100;
        drawWaveform(canvas, refBuffer, refStartSample);
        
        // Setup interaction after buffer is loaded
        canvas.onclick = (e) => {
          const rect = canvas.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const newStartSample = Math.floor((x / rect.width) * refBuffer.length);
          refStartSample = newStartSample;
          drawWaveform(canvas, refBuffer, refStartSample);
          if (yourBuffer) analyze(); // Only analyze if both files are loaded
        };

        // Setup play button
        setupPlayButton(document.getElementById("refPlayButton"), refBuffer, refStartSample);

        // Run analysis if your file is already loaded
        if (yourBuffer) analyze();
      }
    });
  </script>
  <script src='https://storage.ko-fi.com/cdn/scripts/overlay-widget.js'></script>
  <script>
    kofiWidgetOverlay.draw('royklein', {
      'type': 'floating-chat',
      'floating-chat.donateButton.text': 'Support me',
      'floating-chat.donateButton.background-color': '#00b9fe',
      'floating-chat.donateButton.text-color': '#fff'
    });
  </script>
  <style>
    .floatingchat-container-wrap { left: unset; right: 50px; width: 50%; }
    .floatingchat-container-wrap-mobi { left: unset; right: 50px; width: 50%;}
    .floating-chat-kofi-popup-iframe { left: unset; right: 50px; }
    .floating-chat-kofi-popup-iframe-mobi { left: unset; right: 50px; }
    .floating-chat-kofi-popup-iframe-closer-mobi { left: unset; right: 50px; }
</style>
</body>
</html>
